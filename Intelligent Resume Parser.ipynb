{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b4d824-1892-42b5-9de4-92df507f8253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in d:\\ananconda navi\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\ananconda navi\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in d:\\ananconda navi\\lib\\site-packages (from pytesseract) (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b89ed2d-6c6f-4fcb-87ae-8d1493e0b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf2 in d:\\ananconda navi\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: pdf2image in d:\\ananconda navi\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in d:\\ananconda navi\\lib\\site-packages (from pdf2image) (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2\n",
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9902c8b0-9657-495a-8510-cc84c884d486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tools in d:\\ananconda navi\\lib\\site-packages (0.1.9)\n",
      "Requirement already satisfied: pytils in d:\\ananconda navi\\lib\\site-packages (from tools) (0.4.3)\n",
      "Requirement already satisfied: six in d:\\ananconda navi\\lib\\site-packages (from tools) (1.16.0)\n",
      "Requirement already satisfied: lxml in d:\\ananconda navi\\lib\\site-packages (from tools) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe82c60-4374-49e5-8f63-f2e07818305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dateparser in d:\\ananconda navi\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in d:\\ananconda navi\\lib\\site-packages (from dateparser) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2024.2 in d:\\ananconda navi\\lib\\site-packages (from dateparser) (2025.2)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in d:\\ananconda navi\\lib\\site-packages (from dateparser) (2023.10.3)\n",
      "Requirement already satisfied: tzlocal>=0.2 in d:\\ananconda navi\\lib\\site-packages (from dateparser) (5.3.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ananconda navi\\lib\\site-packages (from python-dateutil>=2.7.0->dateparser) (1.16.0)\n",
      "Requirement already satisfied: tzdata in d:\\ananconda navi\\lib\\site-packages (from tzlocal>=0.2->dateparser) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f887178-d538-4ebe-8d06-61d2d07f6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in d:\\ananconda navi\\lib\\site-packages (1.25.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6956f57-16d4-4b6a-94e4-222030098f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in d:\\ananconda navi\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in d:\\ananconda navi\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in d:\\ananconda navi\\lib\\site-packages (from ollama) (2.11.3)\n",
      "Requirement already satisfied: anyio in d:\\ananconda navi\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in d:\\ananconda navi\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ananconda navi\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in d:\\ananconda navi\\lib\\site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\ananconda navi\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ananconda navi\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in d:\\ananconda navi\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\ananconda navi\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\ananconda navi\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ananconda navi\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7023a022-213c-4d98-940a-e9582ccbec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af7aad0-73bc-42f4-a7f0-a0aacdf4d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"MUGESH SURYA PRADEEP R\",\n",
      "  \"email\": \"mukeshsuryapradeep2@mail.com\",\n",
      "  \"phone\": \"9345563268\",\n",
      "  \"linkedin\": \"linkedin.com\",\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Scikit-learn\",\n",
      "    \"Model Training\",\n",
      "    \"Hyperparameter Tuning\",\n",
      "    \"Cross-validation\",\n",
      "    \"TensorFlow\",\n",
      "    \"PyTorch\",\n",
      "    \"Transformers\",\n",
      "    \"Hugging Face\",\n",
      "    \"LangChain\",\n",
      "    \"NLTK\",\n",
      "    \"SpaCy\",\n",
      "    \"ARIMA\",\n",
      "    \"SARIMA\",\n",
      "    \"Prophet\",\n",
      "    \"LSTM\",\n",
      "    \"Pandas\",\n",
      "    \"NumPy\",\n",
      "    \"Feature Engineering\",\n",
      "    \"ETL Pipelines\",\n",
      "    \"Text processing\",\n",
      "    \"Power BI\",\n",
      "    \"Matplotlib\",\n",
      "    \"Seaborn\",\n",
      "    \"Power BI\",\n",
      "    \"Plotly\",\n",
      "    \"Streamlit\",\n",
      "    \"Gradio\",\n",
      "    \"Selenium\",\n",
      "    \"AWS\",\n",
      "    \"CI/CD\",\n",
      "    \"Model Deployment\",\n",
      "    \"Git\",\n",
      "    \"Pinecone\",\n",
      "    \"FAISS\",\n",
      "    \"ChromaDB\",\n",
      "    \"Retrieval-Augmented Generation (RAG)\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"B.E. Electrical and Electronic Engineering\",\n",
      "      \"institution\": \"Loyola-ICAM College of Engineering and Technology\",\n",
      "      \"year\": \"Nov 2020 \\u2013 July 2024\"\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"IIT-M Pravartak Certified Data Science Course\",\n",
      "      \"institution\": \"GUVI\",\n",
      "      \"year\": \"(July 2024 \\u2013 Dec 2024)\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [],\n",
      "  \"certifications\": [\n",
      "    \"SQL Certification \\u2013 HackerRank\",\n",
      "    \"Python Certification \\u2013 HackerRank\",\n",
      "    \"Machine learning Certification \\u2013 Naan Mudhalvan\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"title\": \"AI-Powered Document Analysis System\",\n",
      "      \"date\": \"(March 2025)\",\n",
      "      \"skills\": [\n",
      "        \"LangChain\",\n",
      "        \"Vector Search\",\n",
      "        \"Ollama LLM\",\n",
      "        \"Streamlit\"\n",
      "      ],\n",
      "      \"description\": \"Developed a PDF-based analysis system using vector embeddings & similarity search. Improved retrieval efficiency by 30% with RecursiveCharacterTextSplitter. Integrated Ollama LLM (DeepSeek-r1:1.5B) for context-aware responses. Optimized search efficiency by 40% using InMemoryVectorStore.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Sentiment Analysis Model \\u2013 AWS Deployment\",\n",
      "      \"date\": \"(January 2025)\",\n",
      "      \"skills\": [\n",
      "        \"Deep Learning\",\n",
      "        \"NLP\",\n",
      "        \"Hugging Face\",\n",
      "        \"AWS\",\n",
      "        \"Gradio\",\n",
      "        \"Model Deployment\"\n",
      "      ],\n",
      "      \"description\": \"Fine-tuned DistilBERT on 50K+ samples, achieving 89.3% accuracy. Deployed a Gradio web app on AWS, handling 1K+ daily users. Reduced inference latency by 40%, storage costs by 25% with AWS (S3, EC2, RDS). Secured 100K+ user logs in Amazon RDS for analysis.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Predictive Purchase System \\u2013 Dominos\",\n",
      "      \"date\": \"(December 2024)\",\n",
      "      \"skills\": [\n",
      "        \"Time Series Forecasting\",\n",
      "        \"ARIMA\",\n",
      "        \"SARIMA\",\n",
      "        \"LSTM\",\n",
      "        \"Prophet\",\n",
      "        \"Python\"\n",
      "      ],\n",
      "      \"description\": \"Achieved a MAPE of 13.3% with time-series forecasting models (ARIMA, SARIMA, LSTM, Prophet) for Dominos. Automated purchase prediction based on sales history and external factors.\"\n",
      "    }\n",
      "  ],\n",
      "  \"confidence\": {\n",
      "    \"name\": 0.95,\n",
      "    \"email\": 1.0,\n",
      "    \"phone\": 1.0,\n",
      "    \"linkedin\": 0.9,\n",
      "    \"skills\": 0.95,\n",
      "    \"education\": 0.9,\n",
      "    \"experience\": 0.0,\n",
      "    \"certifications\": 0.9,\n",
      "    \"projects\": 0.9\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "import ollama\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Step 1: Extract text from PDF or Image\n",
    "def extract_text(file_path):\n",
    "    text = \"\"\n",
    "\n",
    "    # Check file extension\n",
    "    _, ext = os.path.splitext(file_path.lower())\n",
    "\n",
    "    if ext in [\".pdf\"]:\n",
    "        doc = fitz.open(file_path)\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "\n",
    "        if not text.strip():\n",
    "            images = convert_from_path(file_path)\n",
    "            for img in images:\n",
    "                text += pytesseract.image_to_string(img)\n",
    "\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        img = Image.open(file_path)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a PDF or an Image (jpg, png).\")\n",
    "\n",
    "    return text\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"D:\\Tesseract-OCR\\tesseract.exe\"\n",
    "# Step 2: Send text to Ollama (Mistral Model)\n",
    "def query_llm(text):\n",
    "    prompt = f\"\"\"\n",
    "You are a professional resume parser.\n",
    "\n",
    "Given the following RESUME TEXT:\n",
    "\n",
    "{text}\n",
    "\n",
    "Extract and output a JSON with the following fields:\n",
    "\n",
    "{{\n",
    "  \"name\": \"\",\n",
    "  \"email\": \"\",\n",
    "  \"phone\": \"\",\n",
    "  \"linkedin\": \"\",\n",
    "  \"skills\": [],\n",
    "  \"education\": [\n",
    "    {{\n",
    "      \"degree\": \"\",\n",
    "      \"institution\": \"\",\n",
    "      \"year\": \"\"\n",
    "    }}\n",
    "  ],\n",
    "  \"experience\": [\n",
    "    {{\n",
    "      \"company\": \"\",\n",
    "      \"title\": \"\",\n",
    "      \"duration\": \"\",\n",
    "      \"description\": \"\"\n",
    "    }}\n",
    "  ],\n",
    "  \"certifications\": [],\n",
    "  \"projects\": []\n",
    "}}\n",
    "\n",
    "Important Instructions:\n",
    "- Return null for any missing fields.\n",
    "- Normalize all date formats to \"Month YYYY - Month YYYY\" if possible.\n",
    "- Only output valid JSON (no extra text, no explanations).\n",
    "- Keep field names exactly same.\n",
    "\n",
    "Resume Text ends here.\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    content = response['message']['content']\n",
    "    return content\n",
    "\n",
    "# Step 3: Parse the resume\n",
    "def parse_resume(file_path):\n",
    "    text = extract_text(file_path)\n",
    "    raw_response = query_llm(text)\n",
    "\n",
    "    try:\n",
    "        parsed_data = json.loads(raw_response)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON. Here is the raw response:\")\n",
    "        print(raw_response)\n",
    "        parsed_data = None\n",
    "\n",
    "    # Add confidence scores manually\n",
    "    if parsed_data:\n",
    "        parsed_data[\"confidence\"] = {\n",
    "            \"name\": 0.95 if parsed_data.get(\"name\") else 0.0,\n",
    "            \"email\": 1.0 if parsed_data.get(\"email\") else 0.0,\n",
    "            \"phone\": 1.0 if parsed_data.get(\"phone\") else 0.0,\n",
    "            \"linkedin\": 0.9 if parsed_data.get(\"linkedin\") else 0.0,\n",
    "            \"skills\": 0.95 if parsed_data.get(\"skills\") else 0.0,\n",
    "            \"education\": 0.9 if parsed_data.get(\"education\") else 0.0,\n",
    "            \"experience\": 0.9 if parsed_data.get(\"experience\") else 0.0,\n",
    "            \"certifications\": 0.9 if parsed_data.get(\"certifications\") else 0.0,\n",
    "            \"projects\": 0.9 if parsed_data.get(\"projects\") else 0.0\n",
    "        }\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "# Step 4: Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r\"C:\\Users\\91934\\Desktop\\MOVIES\\Mugeshsuryapradeep__AIML ENGINEER..pdf\" # <-- Update your path\n",
    "    result = parse_resume(file_path)\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
